{"content": "```markdown\n## Setup and Development\n\n### Prerequisites\n\nBefore setting up the development environment, ensure you have the following prerequisites installed on your system:\n\n- **Python**: Version 3.9 or higher but less than 3.12. You can download it from [python.org](https://www.python.org/downloads/).\n- **pip**: Python package manager, usually included with Python installations.\n- **Git**: Version control system to clone the repository. Download it from [git-scm.com](https://git-scm.com/).\n\n### Environment Setup\n\n1. **Clone the Repository**: Open your terminal and run the following command to clone the repository:\n   ```bash\n   git clone https://github.com/DivergerThinking/codeas.git\n   ```\n2. **Navigate to the Project Directory**: Change into the project directory:\n   ```bash\n   cd codeas\n   ```\n3. **Create a Virtual Environment**: It's recommended to use a virtual environment to manage dependencies:\n   ```bash\n   python -m venv venv\n   ```\n4. **Activate the Virtual Environment**:\n   - On Windows:\n     ```bash\n     .\\venv\\Scripts\\activate\n     ```\n   - On macOS and Linux:\n     ```bash\n     source venv/bin/activate\n     ```\n\n### Dependencies\n\nInstall the required dependencies listed in the `requirements.txt` file:\n```bash\npip install -r requirements.txt\n```\n\n### Build Process\n\nThe project uses a Makefile to automate styling checks. To run the style checks, execute:\n```bash\nmake style\n```\n\n### Configuration Files\n\n- **`.env` File**: Create a `.env` file in the root directory to store environment variables such as the OpenAI API key.\n  ```bash\n  echo \"OPENAI_API_KEY=your_openai_api_key\" > .env\n  ```\n- **`settings.yaml`**: Configuration settings for the application are stored in `.codeas/settings.yaml`. Modify this file to change model configurations, agent settings, and codebase parsing options.\n\n### Code Style and Standards\n\nThe project follows the PEP 8 style guide for Python code. The following tools are used to enforce code style and quality:\n\n- **Black**: Automatically formats Python code to conform to PEP 8.\n- **isort**: Sorts and organizes imports.\n- **Ruff**: Lints Python code for errors and style issues.\n\nRun the following command to apply code style checks and fixes:\n```bash\nmake style\n```\n\nEnsure your code adheres to these standards before committing changes.\n```\n", "cost": {"input_cost": 0.05644, "output_cost": 0.00813, "total_cost": 0.06457}, "tokens": {"input_tokens": 11288, "output_tokens": 542, "total_tokens": 11830}, "messages": [{"role": "user", "content": "# requirements.txt:\nopenai>=1.0.0\npydantic>=2.3\npyyaml>=6.0.1\npython-dotenv>=1.0.0\npyperclip>=1.8.2\ntiktoken>=0.5.1\ntree_sitter==0.20.2\ntree-sitter-languages>=1.8.0\nprompt-toolkit>=3.0.3\nrich>=13.7.0\n\n# Makefile:\nstyle:\n\t@echo \"Run black\" && \\\n\tblack . && \\\n\techo \"Run isort\" && \\\n\tisort . && \\\n\techo \"Run ruff\" && \\\n\truff . --fix\n\n# pyproject.toml:\n[build-system]\nrequires = [\"setuptools\", \"setuptools-scm\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"codeas\"\nauthors = [\n    {name = \"Manuel Renner\", email = \"manuel.renner@diverger.ai\"},\n]\nlicense = {text = \"MIT License\"}\ndescription = \"Improve your codebase with LLMs using the right context for the right prompts.\"\nrequires-python = \">=3.9,<3.12\"\ndynamic = [\"version\", \"readme\", \"dependencies\"]\n\n[project.urls]\nSource = 'https://github.com/DivergerThinking/codeas'\nHomepage = 'https://diverger.ai'\n\n[project.scripts]\ncodeas = 'codeas.terminal:start_terminal'\n\n[tool.setuptools.dynamic]\nversion = {attr = \"codeas.__version__\"}\nreadme = {file=[\"README.md\"], content-type=\"text/markdown\"}\ndependencies = {file = [\"requirements.txt\"]}\n\n[tool.isort]\nprofile = \"black\"\n\n[tool.ruff.lint.per-file-ignores]\n\"src/codeas/ui/page_ui.py\" = [\"F401\"]\n\n# README.md:\n# codeas\n\ncodeas stands for CODEbase ASsistant. It boosts your software development processes by leveraging LLMs using your full codebase as context.\n\n## Why this tool \u2753\n\nThere are a lot of existing AI tools for software development, each of which has its capabilities and limitations. <br>\nAt [Diverger](https://diverger.ai/) we decided to build our own AI tool for software development to help us where other tools can't. We chose to share it with the open-source community so that other developers can benefit from it. Any feedback and/or contribution is welcome. Happy coding!\n\n##  \ud83d\udee0\ufe0f Installation\n\n```bash\npip install codeas\n```\n\n#### OpenAI key\nCurrently, the tool only supports OpenAI as a provider.\nTo add your OpenAI key, export it as an environment variable via the terminal:\n\n```bash\nexport OPENAI_API_KEY=\"...\"\n```\n\n## \ud83d\udcbb Usage\n\n### Chat interface\n\nYou can start the chat interface by running the following command in your terminal:\n\n```bash\ncodeas\n```\n\nThis will open a chat interface that you can use to ask questions to your assistant, interact with your codebase through agents and run commands.\n\n```text\n> [ask the assistant what you want]\n```\n\n### Agents\n\nAgents use OpenAI's function calling to interact with the codebase. They are triggered through the use of \"@\" in your prompts. Example:\n```text\n> @add src/codeas/codebase.py structure\n```\nThe above command adds the structure of src/codeas/codebase.py as context to the chat conversation. To view the context currently added to the conversation you can use the /view command.\n\nThe following agents are currently supported:\n- `@add`: adds context from your codebase to the conversation\n- `@write` - writes content to files in your codebase\n- `@search` - searches through your codebase for given code\n\nSee **Agents Usage Examples** for more info on how to use agents\n\n### Commands\n\nCommands can be used to perform specific actions that add some functionalities to the tool yet do not require the use of LLMs. The following commands are available\n\n- `/view`: prints the context currently used in the conversation to the console. Use this command to check that the correct context for your request was added to the conversation properly\n- `/clear`: clears the context and chat history from the conversation. Use this command when you don't need the previous context anymore, this helps reduce costs by removing unnecessary tokens given to the LLM\n- `/copy`: adds the last message to your clipboard.\n- `/tree`: prints the tree directory currently used by the codebase parser. See codebase settings for more information. \n- `/exit`: exits the chat interface. The same can be achieved using `ctrl + C`\n\n### Settings\n\nSettings are stored inside ``.codeas/settings.yaml`` after the first time. <br>\n**IMPORTANT NOTE**: restart the chat interface after changing. <br>\n\nThe following settings are available:\n- ``chat_config``: configures model and temperature to use for chat assistant. gpt-3.5-turbo-1106 is used by default as it is faster, cheaper and produces reasonably good results.\n- ``agent_configs``: configures model and temperature to use for each agent. gpt-4-1106-preview is used by default as it works best for function calls. \n- ``codebase_config``: configures which files are parsed when retrieving context from your codebase. By default, only **file extensions [.py, .java, .js, .ts, .cs, .rs, .rb, .c, .go, .php] are included** and **files starting with \".\" and \"__\" are excluded**. <br> **IMPORTANT NOTE**: parsing of the code structure of the files, functions and classes is currently only **supported for **python** files**. Use `/tree` command to check which files are included.\n\n### Agent Usage Examples:\n\n**`@add` examples**:\n\nAdding a file:\n```text\n> @add src/codeas/codebase.py\n```\nAdding the code structure of a file \n```text\n> @add structure of src/codeas/codebase.py\n```\nAdding all files in a directory \n```text\n> @add files under src/codeas directory\n```\nAdding given lines of a file \n```text\n> @add src/codeas/codebase.py l1-100\n```\nAdding specific class/function \n```text\n> @add src/codeas/codebase Codebase class\n```\n\nNOTE: you can combine the above prompts in one request and use your own wording.\n\n**`@write` examples**:\nWriting markdown documentation to a new file:\n```text\n> @write markdown documentation for the given context inside docs/my_docu.md\n```\nWriting tests to a new file:\n```text\n> @write tests for the given classes using pytest. Write the tests inside tests/my_class.py\n```\nWriting functions to an existing file:\n```text\n> @write a function to read a file and append it to src/codeas/utils.py\n```\n\nNOTE: you can also first generate docs, tests, etc. without the @write and use /copy command to add the output to your clipboard\n\n**`@search` examples**:\nSearching through some functionality:\n```text\n> @search the sections of code related to parsing a codebase\n```\nSearching for a given class/function:\n```text\n> @search which class or function is responsible for starting the terminal interface\n```\n\nNOTE: this feature is relatively experimental and may not work so well on large codebases.\n\n## \ud83d\ude80 Releases\n\n### v0.3.0 (15.01.2023)\nUse AI agents to better interact with the codebase\n\n**Release notes**\n- Integrates agents using OpenAI tool calling to better interact with codebase \n- Adds commands to improve usability and transparency of the tool\n- Improves context retrieval options with possibility to only add file structure or sections of a file\n- Improves console output for better UX\n\n### v0.2.0 (22.11.2023)\nEnables context retrieval and file creation to be more dynamic, making the tool act as an agent on your codebase.\n\n**Release notes**\n- Dynamic context retrieval: specify the files you want the LLM to use in your prompt\n- Dynamic file creation: specify the files you want the LLM to create and where.\n- Dynamic guideline selection: add guidelines in prompts.yaml and let the LLM decide which ones are relevant to each of your requests \n- Cross-language support: automatic file parsing for the most popular programming languages (.ts, .js, .py, .cs, .rb, .rs, .java, .go, .c, .php)\n- Multiple file context: multiple files can be used at once within the context\n\n### v0.1.0 (24.10.2023)\nFirst release that supports simple use cases.\n\n**Release notes**:\n- Focused on simple use cases such as adding docstrings to your code, generating tests and creating markdown documentations (feel free to try more complex use cases)\n- Only supports python codebases\n\n# src/codeas/ui/components/deployment_ui.py:\nimport streamlit as st\n\nfrom codeas.core.state import state  # Add this import\nfrom codeas.use_cases.deployment import define_deployment, generate_deployment\n\n\ndef display():\n    use_previous_outputs_strategy = st.toggle(\n        \"Use previous outputs\", value=True, key=\"use_previous_outputs_strategy\"\n    )\n\n    if st.button(\n        \"Define deployment requirements\",\n        type=\"primary\",\n        key=\"define_deployment_strategy\",\n    ):\n        with st.spinner(\"Defining deployment requirements...\"):\n            if use_previous_outputs_strategy:\n                try:\n                    previous_output = state.read_output(\"deployment_strategy.json\")\n                    st.session_state.outputs[\"deployment_strategy\"] = type(\n                        \"Output\",\n                        (),\n                        {\n                            \"response\": {\"content\": previous_output[\"content\"]},\n                            \"cost\": previous_output[\"cost\"],\n                            \"tokens\": previous_output[\"tokens\"],\n                            \"messages\": previous_output[\"messages\"],  # Add this line\n                        },\n                    )\n                except FileNotFoundError:\n                    st.warning(\n                        \"No previous output found for deployment strategy. Running generation...\"\n                    )\n                    st.session_state.outputs[\n                        \"deployment_strategy\"\n                    ] = define_deployment()\n                    # Write the output to a file\n                    state.write_output(\n                        {\n                            \"content\": st.session_state.outputs[\n                                \"deployment_strategy\"\n                            ].response[\"content\"],\n                            \"cost\": st.session_state.outputs[\n                                \"deployment_strategy\"\n                            ].cost,\n                            \"tokens\": st.session_state.outputs[\n                                \"deployment_strategy\"\n                            ].tokens,\n                            \"messages\": st.session_state.outputs[\n                                \"deployment_strategy\"\n                            ].messages,  # Add this line\n                        },\n                        \"deployment_strategy.json\",\n                    )\n            else:\n                st.session_state.outputs[\"deployment_strategy\"] = define_deployment()\n                # Write the output to a file\n                state.write_output(\n                    {\n                        \"content\": st.session_state.outputs[\n                            \"deployment_strategy\"\n                        ].response[\"content\"],\n                        \"cost\": st.session_state.outputs[\"deployment_strategy\"].cost,\n                        \"tokens\": st.session_state.outputs[\n                            \"deployment_strategy\"\n                        ].tokens,\n                        \"messages\": st.session_state.outputs[\n                            \"deployment_strategy\"\n                        ].messages,  # Add this line\n                    },\n                    \"deployment_strategy.json\",\n                )\n\n    if st.button(\"Preview\", key=\"preview_deployment_strategy\"):\n        preview_strategy = define_deployment(preview=True)\n        with st.expander(\"Deployment strategy [Preview]\", expanded=True):\n            st.info(\n                f\"Input cost: ${preview_strategy.cost['input_cost']:.4f} ({preview_strategy.tokens['input_tokens']:,} input tokens)\"\n            )\n            with st.expander(\"Messages\", expanded=False):\n                st.json(preview_strategy.messages)\n\n    if \"deployment_strategy\" in st.session_state.outputs:\n        with st.expander(\"Deployment strategy\", expanded=True):\n            output = st.session_state.outputs[\"deployment_strategy\"]\n            st.info(\n                f\"Total cost: ${output.cost['total_cost']:.4f} \"\n                f\"(input tokens: {output.tokens['input_tokens']:,}, \"\n                f\"output tokens: {output.tokens['output_tokens']:,})\"\n            )\n            with st.expander(\"Messages\", expanded=False):\n                st.json(output.messages)\n            st.markdown(output.response[\"content\"])\n\n        display_generate_deployment()\n\n\ndef display_generate_deployment():\n    use_previous_outputs_deployment = st.toggle(\n        \"Use previous outputs\", value=True, key=\"use_previous_outputs_deployment\"\n    )\n\n    if st.button(\n        \"Generate Terraform code\", type=\"primary\", key=\"generate_terraform_code\"\n    ):\n        with st.spinner(\"Generating Terraform code...\"):\n            deployment_strategy = st.session_state.outputs[\n                \"deployment_strategy\"\n            ].response[\"content\"]\n            if use_previous_outputs_deployment:\n                try:\n                    previous_output = state.read_output(\"terraform_code.json\")\n                    st.session_state.outputs[\"terraform_code\"] = type(\n                        \"Output\",\n                        (),\n                        {\n                            \"response\": {\"content\": previous_output[\"content\"]},\n                            \"cost\": previous_output[\"cost\"],\n                            \"tokens\": previous_output[\"tokens\"],\n                            \"messages\": previous_output[\"messages\"],  # Add this line\n                        },\n                    )\n                except FileNotFoundError:\n                    st.warning(\n                        \"No previous output found for Terraform code. Running generation...\"\n                    )\n                    st.session_state.outputs[\"terraform_code\"] = generate_deployment(\n                        deployment_strategy\n                    )\n                    # Write the output to a file\n                    state.write_output(\n                        {\n                            \"content\": st.session_state.outputs[\n                                \"terraform_code\"\n                            ].response[\"content\"],\n                            \"cost\": st.session_state.outputs[\"terraform_code\"].cost,\n                            \"tokens\": st.session_state.outputs[\"terraform_code\"].tokens,\n                            \"messages\": st.session_state.outputs[\n                                \"terraform_code\"\n                            ].messages,  # Add this line\n                        },\n                        \"terraform_code.json\",\n                    )\n            else:\n                st.session_state.outputs[\"terraform_code\"] = generate_deployment(\n                    deployment_strategy\n                )\n                # Write the output to a file\n                state.write_output(\n                    {\n                        \"content\": st.session_state.outputs[\"terraform_code\"].response[\n                            \"content\"\n                        ],\n                        \"cost\": st.session_state.outputs[\"terraform_code\"].cost,\n                        \"tokens\": st.session_state.outputs[\"terraform_code\"].tokens,\n                        \"messages\": st.session_state.outputs[\n                            \"terraform_code\"\n                        ].messages,  # Add this line\n                    },\n                    \"terraform_code.json\",\n                )\n\n    if st.button(\"Preview\", key=\"preview_terraform_code\"):\n        deployment_strategy = st.session_state.outputs[\"deployment_strategy\"].response[\n            \"content\"\n        ]\n        preview_terraform = generate_deployment(deployment_strategy, preview=True)\n        with st.expander(\"Terraform code [Preview]\", expanded=True):\n            st.info(\n                f\"Input cost: ${preview_terraform.cost['input_cost']:.4f} ({preview_terraform.tokens['input_tokens']:,} input tokens)\"\n            )\n            with st.expander(\"Messages\", expanded=False):\n                st.json(preview_terraform.messages)\n\n    if \"terraform_code\" in st.session_state.outputs:\n        with st.expander(\"Terraform code\", expanded=True):\n            output = st.session_state.outputs[\"terraform_code\"]\n            st.info(\n                f\"Total cost: ${output.cost['total_cost']:.4f} \"\n                f\"(input tokens: {output.tokens['input_tokens']:,}, \"\n                f\"output tokens: {output.tokens['output_tokens']:,})\"\n            )\n            with st.expander(\"Messages\", expanded=False):\n                st.json(output.messages)\n            st.markdown(output.response[\"content\"])\n\n\n# src/codeas/ui/components/page_ui.py:\nfrom typing import Literal\n\nimport streamlit as st\nimport streamlit_nested_layout  # noqa\n\nfrom codeas.core.state import state\nfrom codeas.ui.components import (\n    deployment_ui,\n    documentation_ui,\n    metadata_ui,\n    refactoring_ui,\n    repo_ui,\n    testing_ui,\n)\n\npages = {\n    \"Documentation\": {\"name\": \"\ud83d\udcda Documentation\", \"ui\": documentation_ui},\n    \"Deployment\": {\"name\": \"\ud83d\ude80 Deployment\", \"ui\": deployment_ui},\n    \"Testing\": {\"name\": \"\ud83e\uddea Testing\", \"ui\": testing_ui},\n    \"Refactoring\": {\"name\": \"\ud83d\udd04 Refactoring\", \"ui\": refactoring_ui},\n}\n\n\ndef display(\n    name: Literal[\"Documentation\", \"Deployment\", \"Testing\", \"Refactoring\"],\n):\n    st.subheader(pages[name][\"name\"])\n    state.update_current_page(name)\n    repo_ui.display()\n    metadata_ui.display()\n    pages[name][\"ui\"].display()\n\n\n# src/codeas/ui/pages/2_\ud83d\ude80_Deployment.py:\nfrom codeas.ui.components import page_ui\nfrom codeas.ui.ui_state import init_ui_state\n\ninit_ui_state()\n\npage_ui.display(\"Deployment\")\n\n\n# src/codeas/core/llm.py:\nimport asyncio\nimport logging\n\nfrom openai import AsyncOpenAI, OpenAI\nfrom tenacity import retry, stop_after_attempt\n\nfrom codeas.configs.llm_params import OPENAI_PARAMS  # Import the parameters\n\n\ndef log_retry(retry_state):\n    logging.info(\n        \"Retrying %s: attempt #%s ended with: %s\",\n        retry_state.fn,\n        retry_state.attempt_number,\n        retry_state.outcome,\n    )\n\n\nclass LLMClient:\n    batch_size: int = 100\n    max_retries: int = 5\n\n    def __init__(self):\n        self._client = OpenAI(max_retries=self.max_retries)\n        self.temperature = OPENAI_PARAMS[\"temperature\"]\n        self.top_p = OPENAI_PARAMS[\"top_p\"]\n        self.stream = OPENAI_PARAMS[\"stream\"]\n        self.timeout = OPENAI_PARAMS[\"timeout\"]\n\n    def __enter__(self):  # for context manager\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):  # for context manager\n        if self._client is not None:\n            self._client.close()  # Close the client\n            self._client = None\n\n    def run(self, messages, model=\"gpt-4o-mini\", **kwargs) -> dict:\n        kwargs.setdefault(\"temperature\", self.temperature)\n        kwargs.setdefault(\"top_p\", self.top_p)\n        if not kwargs.get(\"response_format\"):\n            kwargs.setdefault(\"timeout\", self.timeout)\n            kwargs.setdefault(\"stream\", self.stream)\n\n        if model == \"gpt-4o\":\n            model = \"gpt-4o-2024-08-06\"\n            logging.info(\"Using gpt-4o-2024-08-06 model\")\n\n        if isinstance(messages, list):\n            return self.run_completions(messages, model, **kwargs)\n        elif isinstance(messages, dict):\n            return self.run_batch_completions(messages, model, **kwargs)\n\n    def run_completions(self, messages, model=\"gpt-4o-mini\", **kwargs) -> dict:\n        \"\"\"runs completions synchronously\"\"\"\n        if kwargs.get(\"response_format\"):\n            response = self._client.beta.chat.completions.parse(\n                messages=messages, model=model, **kwargs\n            )\n        else:\n            response = self._client.chat.completions.create(\n                messages=messages, model=model, **kwargs\n            )\n        if kwargs.get(\"stream\"):\n            response = self._parse_stream(response)\n        return response\n\n    def _parse_stream(self, stream):\n        \"\"\"parses stream response from completions\"\"\"\n        response = {\"role\": \"assistant\", \"content\": None, \"tool_calls\": None}\n        for chunk in stream:\n            choice = chunk.choices[0]\n            if choice.delta and choice.delta.content:\n                self._parse_delta_content(choice.delta, response)\n            elif choice.delta and choice.delta.tool_calls:\n                self._parse_delta_tools(choice.delta, response)\n        return response\n\n    def run_batch_completions(\n        self, batch_messages: dict, model=\"gpt-4o-mini\", **kwargs\n    ) -> dict:\n        \"\"\"run completions by batch asynchronously\"\"\"\n        return asyncio.run(self._run_batch_completions(batch_messages, model, **kwargs))\n\n    async def _run_batch_completions(\n        self, batch_messages: dict, model: str, **kwargs\n    ) -> dict:\n        \"\"\"runs completions by batch asynchronously\"\"\"\n        async with AsyncOpenAI(max_retries=self.max_retries) as client:\n            coroutines = [\n                self._run_async_completions(client, messages, model, **kwargs)\n                for messages in batch_messages.values()\n            ]\n            responses = []\n            async for batch_responses in self._run_batches(coroutines):\n                responses.extend(batch_responses)\n            return dict(zip(batch_messages.keys(), responses))\n\n    @retry(stop=stop_after_attempt(3), after=log_retry)\n    async def _run_async_completions(self, client, messages, model: str, **kwargs):\n        \"\"\"runs completions asynchronously\"\"\"\n        if kwargs.get(\"response_format\"):\n            response = await client.beta.chat.completions.parse(\n                messages=messages, model=model, **kwargs\n            )\n        else:\n            response = await client.chat.completions.create(\n                messages=messages, model=model, **kwargs\n            )\n        if \"stream\" in kwargs and kwargs[\"stream\"]:\n            response = await self._parse_async_stream(response)\n        return response\n\n    async def _parse_async_stream(self, stream):\n        \"\"\"parses stream response from async completions\"\"\"\n        response = {\"role\": \"assistant\", \"content\": None, \"tool_calls\": None}\n        async for chunk in stream:\n            choice = chunk.choices[0]\n            if choice.delta and choice.delta.content:\n                self._parse_delta_content(choice.delta, response)\n            elif choice.delta and choice.delta.tool_calls:\n                self._parse_delta_tools(choice.delta, response)\n        return response\n\n    async def _run_batches(self, coroutines: list):\n        for batch in self._batches(coroutines, self.batch_size):\n            yield await asyncio.gather(*batch)\n\n    def _batches(self, items, batch_size):\n        for i in range(0, len(items), batch_size):\n            yield items[i : i + batch_size]\n\n    def _parse_delta_content(self, delta, response):\n        if response[\"content\"] is None:\n            response[\"content\"] = \"\"\n\n        response[\"content\"] += delta.content\n\n    def _parse_delta_tools(self, delta, response):\n        if response[\"tool_calls\"] is None:\n            response[\"tool_calls\"] = []\n\n        for tchunk in delta.tool_calls:\n            if len(response[\"tool_calls\"]) <= tchunk.index:\n                response[\"tool_calls\"].append(\n                    {\n                        \"id\": \"\",\n                        \"type\": \"function\",\n                        \"function\": {\"name\": \"\", \"arguments\": \"\"},\n                    }\n                )\n            if tchunk.id:\n                response[\"tool_calls\"][tchunk.index][\"id\"] += tchunk.id\n            if tchunk.function.name:\n                response[\"tool_calls\"][tchunk.index][\"function\"][\n                    \"name\"\n                ] += tchunk.function.name\n            if tchunk.function.arguments:\n                response[\"tool_calls\"][tchunk.index][\"function\"][\n                    \"arguments\"\n                ] += tchunk.function.arguments\n\n\n# src/codeas/configs/prompts.py:\nimport os\n\ngenerate_docs_project_overview = \"\"\"\nGenerate a comprehensive project overview documentation section.\n\nStart with the title '## Project Overview'.\n\nInclude subsections using '### [Subsection Name]' format. Examples of subsections may include (but are not limited to):\n- Purpose and Goals\n- Target Audience\n- Key Features\n- Technology Stack\n- System Architecture Overview\n- Repository Structure\n\nProvide detailed information for each subsection.\n\nIMPORTANT: The output should be directly suitable for a markdown file without any additional explanations or markdown code block tags.\n\"\"\".strip()\n\ngenerate_docs_setup_and_development = \"\"\"\nCreate a detailed setup and development documentation section.\n\nStart with the title '## Setup and Development'.\n\nInclude subsections using '### [Subsection Name]' format. Examples of subsections may include (but are not limited to):\n- Prerequisites\n- Environment Setup\n- Dependencies\n- Build Process\n- Configuration Files\n- Code Style and Standards\n\nProvide clear, step-by-step instructions and explanations for each subsection.\n\nIMPORTANT: The output should be directly suitable for a markdown file without any additional explanations or markdown code block tags.\n\"\"\".strip()\n\ngenerate_docs_architecture = \"\"\"\nProduce a thorough architecture documentation section.\n\nStart with the title '## Architecture'.\n\nInclude subsections using '### [Subsection Name]' format. Examples of subsections may include (but are not limited to):\n- Detailed System Architecture\n- Core Components\n- Main Modules/Classes\n- Key Algorithms\n- Data Structures\n- Design Patterns\n- Business Logic\n- Core Functions\n- Workflow Processes\n- Data Flow\n\nProvide in-depth technical details and explanations for each subsection.\n\nIMPORTANT: The output should be directly suitable for a markdown file without any additional explanations or markdown code block tags.\n\"\"\".strip()\n\ngenerate_docs_ui = \"\"\"\nGenerate a comprehensive UI documentation section.\n\nStart with the title '## User Interface'.\n\nInclude subsections using '### [Subsection Name]' format. Examples of subsections may include (but are not limited to):\n- Component Hierarchy\n- State Management\n- Styling Approach\n- Responsive Design\n- Accessibility Features\n- User Interaction Flows\n\nProvide detailed explanations and examples for each aspect of the UI.\n\nIMPORTANT: The output should be directly suitable for a markdown file without any additional explanations or markdown code block tags.\n\"\"\".strip()\n\ngenerate_docs_db = \"\"\"\nCreate a detailed database documentation section.\n\nStart with the title '## Database'.\n\nInclude subsections using '### [Subsection Name]' format. Examples of subsections may include (but are not limited to):\n- Schema Design\n- Entity-Relationship Diagrams\n- Indexing Strategy\n- Query Optimization\n- Data Models\n- Database Migrations\n\nProvide comprehensive information about the database structure, optimization techniques, and management processes.\n\nIMPORTANT: The output should be directly suitable for a markdown file without any additional explanations or markdown code block tags.\n\"\"\".strip()\n\ngenerate_docs_api = \"\"\"\nProduce a thorough API documentation section.\n\nStart with the title '## API'.\n\nInclude subsections using '### [Subsection Name]' format. Examples of subsections may include (but are not limited to):\n- Endpoints\n- Request/Response Formats\n- Authentication Methods\n- Rate Limiting\n- API Versioning\n- Error Handling for API Responses\n\nProvide detailed descriptions of each API endpoint, including request methods, parameters, response formats, and examples.\n\nIMPORTANT: The output should be directly suitable for a markdown file without any additional explanations or markdown code block tags.\n\"\"\".strip()\n\ngenerate_docs_testing = \"\"\"\nGenerate a comprehensive testing documentation section.\n\nStart with the title '## Testing'.\n\nInclude subsections using '### [Subsection Name]' format. Examples of subsections may include (but are not limited to):\n- Unit Tests\n- Integration Tests\n- End-to-End Tests\n- Test Coverage\n- Mocking Strategies\n- Test Data Management\n- Continuous Integration Testing\n\nProvide detailed information about testing methodologies, tools used, and best practices.\n\nIMPORTANT: The output should be directly suitable for a markdown file without any additional explanations or markdown code block tags.\n\"\"\".strip()\n\ngenerate_docs_deployment = \"\"\"\nCreate a detailed deployment documentation section.\n\nStart with the title '## Deployment'.\n\nInclude subsections using '### [Subsection Name]' format. Examples of subsections may include (but are not limited to):\n- Deployment Process\n- Continuous Integration/Continuous Deployment (CI/CD)\n- Environment-Specific Configurations\n- Scaling Strategies\n- Server Setup\n- Containerization\n- Cloud Service Configurations\n\nProvide step-by-step deployment instructions, configuration details, and best practices.\n\nIMPORTANT: The output should be directly suitable for a markdown file without any additional explanations or markdown code block tags.\n\"\"\".strip()\n\ngenerate_docs_security = \"\"\"\nProduce a thorough security documentation section.\n\nStart with the title '## Security'.\n\nInclude subsections using '### [Subsection Name]' format. Examples of subsections may include (but are not limited to):\n- Authentication Mechanisms\n- Authorization Rules\n- Data Encryption\n- Input Validation\n- CSRF Protection\n- XSS Prevention\n- Security Best Practices\n- Compliance and Regulations\n\nProvide detailed explanations of security measures, implementation details, and compliance requirements.\n\nIMPORTANT: The output should be directly suitable for a markdown file without any additional explanations or markdown code block tags.\n\"\"\".strip()\n\ndefine_testing_strategy = \"\"\"\nAnalyze the given repository structure and create a comprehensive testing strategy by breaking down the test generation process into different steps. \nConsider the following aspects when defining the steps:\n1. Types of tests: Each step should focus on a specific type of test, such as unit tests, integration tests, functional tests, etc.\n2. File relationships: Group related files together to ensure that all of the necessary context is included.\n3. Token limits: Aim to keep each step's input tokens count (the sum of the tokens count of the file paths) under 10,000 tokens unless it is absolutely necessary to exceed it.\n4. Existing tests: If there already exist tests for a given file/class/method, do not include it in the testing step.\n\nFor each testing step, provide:\n- files_paths: A list of file paths to be included for the test generation process\n- type_of_test: The type of test to be performed\n- guidelines: The guidelines to follow for the test generation process (testing framework, focus areas, etc.)\n- test_file_path: The path of the file where the generated tests will be saved. **IMPORTANT**: make sure that the path doesn't already exist.\n\nConsider the following when creating the strategy:\n- Ensure critical components and core functionality are well-covered\n- Balance between different types of tests\n- Prioritize tests that will provide the most value and coverage\n- Consider the complexity and importance of different parts of the codebase\n\"\"\".strip()\n\ngenerate_tests_from_guidelines = \"\"\"\nGenerate comprehensive tests based on the provided guidelines and file contents. \nFollow these instructions carefully:\n1. Create tests according to the 'type of test' and 'guidelines' provided.\n2. Write the complete test code, including all necessary imports, in code blocks.\n3. Provide a brief explanation for each test or group of tests you generate.\n\nIMPORTANT:\n- All code must be contained within code blocks.\n- The code blocks should contain the full, runnable test code in the correct order.\n- Include ALL necessary imports at the beginning of the code.\n- Do not include any code outside of the code blocks.\n- The entire content of the code blocks will be extracted and written to a file, so ensure it's complete and correct.\n\nBegin with a brief overview of the tests you're creating, then proceed with the test code and explanations.\n\"\"\".strip()\n\ndefine_refactoring_files = \"\"\"\nYou are an expert software architect tasked with grouping related files for a refactoring project. Your goal is to create logical groups of files that are closely related and should be refactored together. Follow these guidelines:\n\n1. Analyze the given files and their contents to understand their relationships and dependencies.\n2. Group files based on their functional similarities, shared responsibilities, and interdependencies.\n3. Ensure that each file is placed in exactly one group - no file should appear in multiple groups.\n4. Create as many groups as necessary to logically organize all the files.\n5. Consider the following factors when grouping files:\n   - Shared imports or dependencies\n   - Similar naming conventions or prefixes\n   - Files that implement related features or functionality\n   - Files that belong to the same module or package\n   - Files that operate on the same data structures or models\n\nEnsure that all files from the input are included in the groups, and that the grouping is logical and conducive to efficient refactoring.\n\nReturn the groups as a list of FileGroup objects, each FileGroup containing a list of the file paths contained in the group and a unique descriptive name for that group.\n\"\"\".strip()\n\ngenerate_proposed_changes = \"\"\"\nAs an expert software architect, your task is to propose refactoring changes for a group of related files. Analyze the provided files and suggest improvements to enhance code quality, maintainability, and adherence to best practices. Follow these guidelines:\n\n1. Examine the code structure, design patterns, and overall architecture of the files.\n2. Identify areas for improvement, such as:\n   - Code duplication\n   - Overly complex methods or classes\n   - Poorly named variables, functions, or classes\n   - Violation of SOLID principles\n   - Inefficient algorithms or data structures\n   - Lack of proper error handling\n   - Inconsistent coding style\n3. Propose specific refactoring changes for each file.\n4. Provide a brief explanation for each proposed change, highlighting its benefits.\n\nReturn your response in a structured format with\n- file_path: <path to the file>\n- changes: <proposed changes for that file>\n\nEXAMPLE STRUCTURE FOR PROPOSED CHANGES:\n\n1. <Refactoring suggestion 1>\n   Explanation: <Brief explanation of the issue and proposed solution>\n   ```<language>\n   // Original code\n   <problematic code snippet>\n\n   // Refactored code\n   <improved code snippet>\n   ```\n2. <Refactoring suggestion 2>\n   Explanation: <Brief explanation of the issue and proposed solution>\n   ...\n\nOnly include code snippets if you think it is relevant. The above is only an example of what the structure of your response might look like.\nIMPORTANT: Remember to consider the context of the entire group of files when making suggestions, as some refactoring changes may have implications across multiple files.\n\"\"\".strip()\n\ngenerate_diffs = \"\"\"\nAs an expert software architect, your task is to implement the proposed refactoring changes for a single file. You will be provided with the original file content and the proposed changes. Your goal is to generate a diff that represents the necessary changes.\n\nFollow these guidelines:\n\n1. Carefully review the original file content and the proposed changes.\n2. Generate a diff that accurately represents the proposed changes.\n3. Use unified diff format for the file.\n4. Include only the changed parts of the file in the diff.\n5. Ensure that applying this diff will result in the desired refactored code.\n\nEXAMPLE OF PROPOSED CHANGES:\n\n1. Add an imports of sympy.\n2. Remove the is_prime() function.\n3. Replace the existing call to is_prime() with a call to sympy.isprime().\n\nEXAMPLE OF DIFF OUTPUT:\n\n```diff\n--- mathweb/flask/app.py\n+++ mathweb/flask/app.py\n@@ ... @@\n-class MathWeb:\n+import sympy\n+\n+class MathWeb:\n@@ ... @@\n-def is_prime(x):\n-    if x < 2:\n-        return False\n-    for i in range(2, int(math.sqrt(x)) + 1):\n-        if x % i == 0:\n-            return False\n-    return True\n@@ ... @@\n-@app.route('/prime/<int:n>')\n-def nth_prime(n):\n-    count = 0\n-    num = 1\n-    while count < n:\n-        num += 1\n-        if is_prime(num):\n-            count += 1\n-    return str(num)\n+@app.route('/prime/<int:n>')\n+def nth_prime(n):\n+    count = 0\n+    num = 1\n+    while count < n:\n+        num += 1\n+        if sympy.isprime(num):\n+            count += 1\n+    return str(num)\n```\n\nFILE EDITING RULES:\n- Include the first 2 lines with the file paths.\n- Don't include timestamps with the file paths.\n- Start a new hunk for each section of the file that needs changes.\n- Start each hunk of changes with a `@@ ... @@` line. (Don't include line numbers like `diff -U0` does.)\n- Mark all new or modified lines with `+`.\n- Mark all lines that need to be removed with `-`.\n- Only output hunks that specify changes with `+` or `-` lines.\n- IMPORTANT: MAKE SURE THAT ALL CHANGES START WITH A `+` OR `-`!\n- Indentation matters in the diffs!\n- When editing a function, method, loop, etc use a hunk to replace the *entire* code block. Delete the entire existing version with `-` lines and then add a new, updated version with `+` lines.\n-To move code within a file, use 2 hunks: 1 to delete it from its current location, 1 to insert it in the new location.\n- Your output should be ONLY the unified diff, without any explanations or additional text.\n\"\"\".strip()\n\ndefine_aws_deployment = \"\"\"\nBased on the provided context about the repository, suggest an AWS deployment strategy for the application. Your response should include:\n\n1. Analysis of Requirements\n   - Briefly summarize the key features and requirements of the application.\n\n2. Deployment Options\n   - Propose 2-3 different AWS deployment strategies that could suit the application.\n   - For each option, list the main AWS services involved and their purpose.\n   - Briefly discuss pros and cons of each approach.\n\n3. Recommended Deployment Strategy\n   Provide a detailed recommendation for the best deployment strategy, including:\n   - List of AWS services to be used and their roles in the architecture.\n   - High-level architecture diagram (in text format).\n   - Justification for choosing this strategy over the alternatives.\n   - Considerations for scalability, reliability, and cost-effectiveness.\n\n4. Deployment Components\n   For the recommended strategy, provide details on:\n   - Compute: EC2 instances, ECS, or Lambda functions\n   - Database: RDS, DynamoDB, or other data storage solutions\n   - Networking: VPC configuration, subnets, security groups\n   - Load Balancing: Application Load Balancer or Network Load Balancer\n   - Storage: S3 buckets or EFS\n   - Caching: ElastiCache (if applicable)\n   - CDN: CloudFront (if applicable)\n   - Monitoring and Logging: CloudWatch, X-Ray\n   - CI/CD: CodePipeline, CodeBuild, CodeDeploy\n\n5. Security Considerations\n   - IAM roles and policies\n   - Data encryption (at rest and in transit)\n   - Network security\n\n6. Scaling and High Availability\n   - Auto Scaling configurations\n   - Multi-AZ deployment\n   - Disaster recovery strategy\n\nProvide clear and concise information for each section, focusing on the specific needs of the application as understood from the context. The recommended deployment strategy should be well-defined and detailed enough to serve as a basis for generating Terraform code in the next step.\n\"\"\".strip()\n\ngenerate_aws_deployment = \"\"\"\nBased on the recommended AWS deployment strategy provided, generate comprehensive Terraform code to implement the infrastructure. Your code should cover all the components and services mentioned in the strategy. Follow these guidelines:\n\n1. Structure:\n   - Organize the code into logical files (e.g., main.tf, variables.tf, outputs.tf, modules).\n   - Use modules where appropriate to encapsulate reusable components.\n\n2. Resources:\n   - Include all AWS resources mentioned in the deployment strategy.\n   - Properly configure each resource with necessary settings and best practices.\n\n3. Networking:\n   - Set up the VPC, subnets, security groups, and route tables as described.\n\n4. Compute:\n   - Configure the chosen compute option (EC2, ECS, or Lambda) with appropriate settings.\n\n5. Database:\n   - Set up the recommended database solution (RDS, DynamoDB, etc.) with proper configurations.\n\n6. Storage:\n   - Configure S3 buckets or EFS as specified in the strategy.\n\n7. Load Balancing:\n   - Set up the Application Load Balancer or Network Load Balancer as recommended.\n\n8. Caching and CDN:\n   - Include ElastiCache and/or CloudFront configurations if applicable.\n\n9. Monitoring and Logging:\n   - Set up CloudWatch and X-Ray resources for monitoring and observability.\n\n10. CI/CD:\n    - Configure CodePipeline, CodeBuild, and CodeDeploy resources if mentioned.\n\n11. Security:\n    - Implement IAM roles, policies, and encryption settings as described.\n\n12. Scaling and High Availability:\n    - Include Auto Scaling configurations and multi-AZ setups as recommended.\n\n13. Variables and Outputs:\n    - Use variables for customizable values and define meaningful outputs.\n\n14. Backend Configuration:\n    - Include a backend configuration for storing Terraform state.\n\nProvide the Terraform code in multiple code blocks, organized by file or logical sections. Include comments to explain key configurations and any assumptions made. After the code blocks, briefly explain any important considerations or next steps for applying this Terraform configuration.\n\"\"\".strip()\n\n\ndef load_prompt(prompt_name):\n    prompt_path = f\".codeas/prompts/{prompt_name}.txt\"\n    if not os.path.exists(prompt_path):\n        with open(prompt_path, \"w\") as f:\n            f.write(globals()[prompt_name])\n\n    with open(prompt_path, \"r\") as f:\n        return f.read().strip()\n\n\n# Get all string variables in the current module\nprompt_names = [\n    name\n    for name, value in globals().items()\n    if isinstance(value, str) and not name.startswith(\"__\")\n]\n\n# Ensure the prompts directory exists\nos.makedirs(\".codeas/prompts\", exist_ok=True)\n\n# Load all prompts\nfor prompt_name in prompt_names:\n    globals()[prompt_name] = load_prompt(prompt_name)\n\n\n# src/codeas/configs/agents_configs.py:\nfrom codeas.configs import prompts\nfrom codeas.core.agent import FileDetailsOutput, FilePathsOutput\n\nAGENTS_CONFIGS = {\n    \"custom\": {\n        \"system_prompt\": prompts.BASE_SYSTEM_PROMPT,\n        \"instructions\": \"\",\n        \"model\": \"gpt-4o-2024-08-06\",\n        \"context\": \"files_content\",\n    },\n    \"generate_docs_backend\": {\n        \"system_prompt\": prompts.BASE_SYSTEM_PROMPT,\n        \"instructions\": prompts.GENERATE_BACKEND_DOCS,\n        \"model\": \"gpt-4o-2024-08-06\",\n        \"context\": \"files_description\",\n    },\n    \"generate_docs_frontend\": {\n        \"system_prompt\": prompts.BASE_SYSTEM_PROMPT,\n        \"instructions\": prompts.GENERATE_FRONTEND_DOCS,\n        \"model\": \"gpt-4o-2024-08-06\",\n        \"context\": \"files_description\",\n    },\n    \"generate_docs_mobile\": {\n        \"system_prompt\": prompts.BASE_SYSTEM_PROMPT,\n        \"instructions\": prompts.GENERATE_MOBILE_DOCS,\n        \"model\": \"gpt-4o-2024-08-06\",\n        \"context\": \"files_description\",\n    },\n    \"generate_detailed_technical_docs\": {\n        \"system_prompt\": prompts.BASE_SYSTEM_PROMPT,\n        \"instructions\": prompts.GENERATE_DETAILED_TECHNICAL_DOCS,\n        \"model\": \"gpt-4o-2024-08-06\",\n        \"context\": \"files_detail\",\n    },\n    \"generate_config_docs\": {\n        \"system_prompt\": prompts.BASE_SYSTEM_PROMPT,\n        \"instructions\": prompts.GENERATE_CONFIG_DOCS,\n        \"model\": \"gpt-4o-2024-08-06\",\n        \"context\": \"files_content\",\n        \"auto_select\": True,\n    },\n    \"generate_unit_tests_python\": {\n        \"system_prompt\": prompts.BASE_SYSTEM_PROMPT,\n        \"instructions\": prompts.GENERATE_UNIT_TESTS_PYTHON,\n        \"model\": \"gpt-4o-2024-08-06\",\n        \"context\": \"files_content\",\n        \"batch\": True,\n    },\n    \"generate_functional_tests_python\": {\n        \"system_prompt\": prompts.BASE_SYSTEM_PROMPT,\n        \"instructions\": prompts.GENERATE_FUNCTIONAL_TESTS_PYTHON,\n        \"model\": \"gpt-4o-2024-08-06\",\n        \"context\": \"files_content\",\n    },\n    \"generate_file_refactor\": {\n        \"system_prompt\": prompts.BASE_SYSTEM_PROMPT,\n        \"instructions\": prompts.GENERATE_FILE_REFACTOR,\n        \"model\": \"gpt-4o-2024-08-06\",\n        \"context\": \"files_content\",\n        \"batch\": True,\n    },\n    \"generate_repo_refactor\": {\n        \"system_prompt\": prompts.BASE_SYSTEM_PROMPT,\n        \"instructions\": prompts.GENERATE_REPO_REFACTOR,\n        \"model\": \"gpt-4o-2024-08-06\",\n        \"context\": \"files_content\",\n    },\n    \"suggest_aws_deployment\": {\n        \"system_prompt\": prompts.BASE_SYSTEM_PROMPT,\n        \"instructions\": prompts.SUGGEST_AWS_DEPLOYMENT,\n        \"model\": \"gpt-4o-2024-08-06\",\n        \"context\": \"files_detail\",\n    },\n    \"generate_aws_terraform\": {\n        \"system_prompt\": prompts.BASE_SYSTEM_PROMPT,\n        \"instructions\": prompts.GENERATE_AWS_TERRAFORM,\n        \"model\": \"gpt-4o-2024-08-06\",\n        \"context\": \"files_detail\",\n        \"use_previous_outputs\": True,\n    },\n    \"extract_files_description\": {\n        \"system_prompt\": prompts.BASE_SYSTEM_PROMPT,\n        \"instructions\": prompts.EXTRACT_FILE_DESCRIPTION,\n        \"model\": \"gpt-4o-mini\",\n        \"context\": \"files_content\",\n        \"batch\": True,\n    },\n    \"extract_files_detail\": {\n        \"system_prompt\": prompts.BASE_SYSTEM_PROMPT,\n        \"instructions\": prompts.EXTRACT_FILE_DETAIL,\n        \"model\": \"gpt-4o-mini\",\n        \"context\": \"files_content\",\n        \"response_format\": FileDetailsOutput,\n        \"batch\": True,\n    },\n    \"auto_select_files\": {\n        \"system_prompt\": prompts.BASE_SYSTEM_PROMPT,\n        \"instructions\": prompts.AUTO_SELECT_FILES,\n        \"model\": \"gpt-4o-2024-08-06\",\n        \"context\": \"files_description\",\n        \"response_format\": FilePathsOutput,\n    },\n}\n\n\n# src/codeas/configs/llm_params.py:\nOPENAI_PARAMS = {\n    \"temperature\": 0.3,\n    \"top_p\": 0.7,\n    \"stream\": True,\n    \"timeout\": 10,\n}\n\n\n# src/codeas/use_cases/documentation.py:\nfrom codeas.configs import prompts\nfrom codeas.core.agent import Agent\nfrom codeas.core.llm import LLMClient\nfrom codeas.core.metadata import RepoMetadata\nfrom codeas.core.repo import Repo\nfrom codeas.core.retriever import ContextRetriever\n\nDOCS_MODEL = \"gpt-4o\"\nSECTION_CONFIG = {\n    \"project_overview\": {\n        \"context\": {\"include_all_files\": True, \"use_descriptions\": True},\n        \"prompt\": prompts.generate_docs_project_overview,\n        \"model\": DOCS_MODEL,\n    },\n    \"setup_and_development\": {\n        \"context\": {\"include_config_files\": True, \"include_deployment_files\": True},\n        \"prompt\": prompts.generate_docs_setup_and_development,\n        \"model\": DOCS_MODEL,\n    },\n    \"architecture\": {\n        \"context\": {\"include_code_files\": True, \"use_details\": True},\n        \"prompt\": prompts.generate_docs_architecture,\n        \"model\": DOCS_MODEL,\n    },\n    \"ui\": {\n        \"context\": {\"include_ui_files\": True, \"use_details\": True},\n        \"prompt\": prompts.generate_docs_ui,\n        \"model\": DOCS_MODEL,\n    },\n    \"db\": {\n        \"context\": {\"include_db_files\": True, \"use_details\": True},\n        \"prompt\": prompts.generate_docs_db,\n        \"model\": DOCS_MODEL,\n    },\n    \"api\": {\n        \"context\": {\"include_api_files\": True, \"use_details\": True},\n        \"prompt\": prompts.generate_docs_api,\n        \"model\": DOCS_MODEL,\n    },\n    \"testing\": {\n        \"context\": {\"include_testing_files\": True, \"use_details\": True},\n        \"prompt\": prompts.generate_docs_testing,\n        \"model\": DOCS_MODEL,\n    },\n    \"deployment\": {\n        \"context\": {\"include_deployment_files\": True, \"use_details\": True},\n        \"prompt\": prompts.generate_docs_deployment,\n        \"model\": DOCS_MODEL,\n    },\n    \"security\": {\n        \"context\": {\"include_security_files\": True, \"use_details\": True},\n        \"prompt\": prompts.generate_docs_security,\n        \"model\": DOCS_MODEL,\n    },\n}\n\n\ndef generate_docs_section(\n    llm_client: LLMClient,\n    section: str,\n    repo: Repo,\n    metadata: RepoMetadata,\n    preview: bool = False,\n) -> str:\n    config = SECTION_CONFIG.get(section)\n    if not config:\n        return f\"Error: Section '{section}' not found in configuration.\"\n\n    retriever = ContextRetriever(**config[\"context\"])\n    context = retriever.retrieve(\n        repo.included_files_paths, repo.included_files_tokens, metadata\n    )\n    agent = Agent(instructions=config[\"prompt\"], model=config[\"model\"])\n    if preview:\n        return agent.preview(context=context)\n    else:\n        return agent.run(llm_client, context=context)\n\n\nif __name__ == \"__main__\":\n    from codeas.core.metadata import RepoMetadata\n    from codeas.core.repo import Repo\n\n    llm_client = LLMClient()\n    repo = Repo(repo_path=\".\")\n    metadata = RepoMetadata.load_metadata(repo_path=\".\")\n    docs = generate_docs_section(llm_client, \"project_overview\", repo, metadata)\n    print(docs)\n\n\n# src/codeas/use_cases/deployment.py:\nfrom codeas.configs import prompts\nfrom codeas.core.agent import Agent\nfrom codeas.core.retriever import ContextRetriever\nfrom codeas.core.state import state\n\n\ndef define_deployment(preview: bool = False) -> str:\n    retriever = ContextRetriever(include_code_files=True, use_descriptions=True)\n    context = retriever.retrieve(\n        state.repo.included_files_paths,\n        state.repo.included_files_tokens,\n        state.repo_metadata,\n    )\n\n    agent = Agent(\n        instructions=prompts.define_aws_deployment,\n        model=\"gpt-4o\",\n    )\n    if preview:\n        return agent.preview(context=context)\n    else:\n        return agent.run(state.llm_client, context=context)\n\n\ndef generate_deployment(deployment_strategy: str, preview: bool = False) -> str:\n    retriever = ContextRetriever(include_code_files=True, use_descriptions=True)\n    context = [\n        retriever.retrieve(\n            state.repo.included_files_paths,\n            state.repo.included_files_tokens,\n            state.repo_metadata,\n        )\n    ]\n    context.append(deployment_strategy)\n    agent = Agent(\n        instructions=prompts.generate_aws_deployment,\n        model=\"gpt-4o\",\n    )\n    if preview:\n        return agent.preview(context=context)\n    else:\n        return agent.run(state.llm_client, context=context)\n\n\n# src/codeas/use_cases/refactoring.py:\nfrom pydantic import BaseModel\n\nfrom codeas.configs import prompts\nfrom codeas.core.agent import Agent\nfrom codeas.core.retriever import ContextRetriever\nfrom codeas.core.state import state\n\n\nclass FileGroup(BaseModel):\n    name: str\n    files_paths: list[str]\n\n\nclass RefactoringGroups(BaseModel):\n    groups: list[FileGroup]\n\n\ndef define_refactoring_files(preview: bool = False):\n    retriever = ContextRetriever(include_code_files=True, use_details=True)\n    context = retriever.retrieve(\n        state.repo.included_files_paths,\n        state.repo.included_files_tokens,\n        state.repo_metadata,\n    )\n\n    agent = Agent(\n        instructions=prompts.define_refactoring_files,\n        model=\"gpt-4o\",\n        response_format=RefactoringGroups,\n    )\n    if preview:\n        return agent.preview(context=context)\n    else:\n        return agent.run(state.llm_client, context=context)\n\n\nclass FileChanges(BaseModel):\n    file_path: str\n    file_changes: str\n\n\nclass ProposedChanges(BaseModel):\n    changes: list[FileChanges]\n\n\ndef generate_proposed_changes(groups: RefactoringGroups, preview: bool = False):\n    contexts = {}\n    for group in groups.groups:\n        retriever = ContextRetriever(include_all_files=True)\n        contexts[group.name] = retriever.retrieve(group.files_paths)\n    agent = Agent(\n        instructions=prompts.generate_proposed_changes,\n        model=\"gpt-4o\",\n        response_format=ProposedChanges,\n    )\n    if preview:\n        return agent.preview(context=contexts)\n    else:\n        return agent.run(state.llm_client, context=contexts)\n\n\ndef generate_diffs(groups_changes: list[ProposedChanges], preview: bool = False) -> str:\n    contexts = {}\n    for proposed_changes in groups_changes:\n        for change in proposed_changes.changes:\n            retriever = ContextRetriever(include_all_files=True)\n            file_content = retriever.retrieve([change.file_path])\n            contexts[change.file_path] = [f\"File content:\\n{file_content}\"]\n            contexts[change.file_path].append(\n                f\"Proposed changes:\\n{change.file_changes}\"\n            )\n\n    agent = Agent(\n        instructions=prompts.generate_diffs,\n        model=\"gpt-4o\",\n    )\n    if preview:\n        return agent.preview(context=contexts)\n    else:\n        return agent.run(state.llm_client, context=contexts)\n"}, {"role": "user", "content": "Create a detailed setup and development documentation section.\n\nStart with the title '## Setup and Development'.\n\nInclude subsections using '### [Subsection Name]' format. Examples of subsections may include (but are not limited to):\n- Prerequisites\n- Environment Setup\n- Dependencies\n- Build Process\n- Configuration Files\n- Code Style and Standards\n\nProvide clear, step-by-step instructions and explanations for each subsection.\n\nIMPORTANT: The output should be directly suitable for a markdown file without any additional explanations or markdown code block tags."}]}